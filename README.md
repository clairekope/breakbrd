# README

## Data File Contents
### `parent_particle_data.pkl`
Information derived from particles and satellite status for subhalos with 1e10 Msun &lt; Mstar &lt; 1e12 Msun & half mass radius &gt; 2 kpc.
```python3
import pickle

with open('parent_particle_data.pkl', 'rb') as f:
    particle_data = pickle.load(f)
```

## Python Scripts
- **download_cutouts** and **download_fits** are for bulk downloading particle cutouts and mock FITs files, respectively. Will exit if using local snapshot data (`--local` flag).
- **particle_info**
- **stellar_spectra** generates the mock spectra with FSPS, and will either include or disclude dust or the instantaneous SFR.
- **get_magnitudes**
- **disk_color**
- **get_d4000** post-processes all FSPS spectra of the inner 2 kpc to calculate the D4000 measure (uses Tjitske's function) and saves them in the appropriate `d4000` CSV file (depending on inclusion of dust and instantaneous SFR).
- **galaxy_density**
- **utilities** contains helper functions for downloading Illustris API data, splitting work among MPI tasks, and dealing with Illustris domain periodicity.

### Script Arguments
All scripts use the same set of command line arguments:

+ `z`: redshift; currently either 0.0 or 0.5
+ `-p`,`--parent`: run the analysis for the parent sample. Replaces a boolean set at the top of some of the scripts.
+ `--no-inst`: override default and don't include instantaneous SFR. Replaces a boolean set at the top of some of the scripts.
+ `--no-dust`: override default don't include dust in the spectra. Replaces a boolean set at the top of some of the scripts.
+ `--tng`: use TNG instead of the original Illustris.
+ `-l`,`--local [DIR]`: use a local copy of the full snapshot. The default is the location on Rusty, and will be set accordingly for the `--tng` flag.
+ `-g`,`--gen-mocks`: use FSPS spectra to determine mock magnitude instead of FITS generated by Illustris team.

### Pipeline

The scripts should be run as laid out in `pipeline.slurm`. All scripts should be run with the same command line arguments as set at the top of `pipeline.slurm`.

## Distributing Work Using MPI and `scatter_work`
```python3
import pickle
from mpi4py import MPI
from utilities import *

comm = MPI.COMM_WORLD
rank = comm.Get_rank()
size = comm.Get_size()

if rank == 0:
    # Assemble the subhalos IDs you want to operate on as a numpy array
    # This example assumes they live in a pickled dictionary
    with open("dict.pkl", "rb") as f:
        dictionary = pickle.read(f)
    subhalo_ids = np.array([k for k in dictionary.keys()])
    
    # Any secondary data to be broadcasted should also be read in on the
    # root processor; for instance, supplementary gas data
    with open("gas_data.pkl", "rb") as f:
        secondary_data = pickle.load(f)
    secondary_data = np.arange(5)
else:
    # Variable names need to be declared for any data you want to distribute
    subhalo_ids = None
    secondary_data = None

# This helper function from utilities.py pads and scatters the arrays
halo_subset = scatter_work(subhalo_ids, rank, size)

# Because scattered arrays have to be the same size, they are padded with -1
good_ids = np.where(halo_subset > -1)[0]

# Broadcast the secondary data normally
secondary_data = comm.bcast(secondary_data, root=0)

my_storage = {} # every rank needs their own way of story results, to be combined later
for halo in halo_subset[good_ids]:
    # do stuff

# Gather the individual results onto one process, stitch together, and save
result_lst = comm.gather(my_storage, root=0)
if rank==0:
    storage = {}
    for dic in result_lst:
        for k, v in dic.items():
            storage[k] = v
    with open("these_results.pkl", "wb") as f:
        pickle.dump(storage, f)
        
# If you want to broadcast the compiled data back out to all processes, add this:
else:
    storage = None
storage = comm.bcast(storage, root=0)

```
